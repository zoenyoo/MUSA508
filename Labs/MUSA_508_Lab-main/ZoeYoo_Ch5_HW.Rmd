---
title: 'Homework 3: Risk Modeling'
author: "Zoe Yoo"
date: "10/29/2021"
output: 
  html_document: 
    toc: true
    toc_float: true
    code_folding: hide
---

```{r setup, include=FALSE, message = FALSE}
knitr::opts_chunk$set(echo = TRUE, warning=FALSE)

library(tidyverse)
library(sf)
library(RSocrata)
library(viridis)
library(spatstat)
library(raster)
library(spdep)
library(FNN)
library(grid)
library(gridExtra)
library(knitr)
library(kableExtra)
library(tidycensus)
# functions
root.dir = "https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/DATA/"
source("https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/functions.r")

```

## 1.1 Read in Data from Chicago

Using the Socrata package and the Chicago OpenData website, I pull the police districts of Chicago, its police beats, Chicago boundary information, and the data on my selected crime. As the homework specified to use a crime that has more selection bias than burglaries, I chose to examine assaults (pulled just from 2019). Assault is often underreported because people choose not to contact the police about it, whether due to fear of retaliation from the perpetrator or a lack of concern (seeing it as "just" a fight, or dismissing it due to gender). Police may have more discretion over whether to actually arrest someone for assault, while burglary is more obviously malicious. 

```{r, message = FALSE, results=FALSE}
policeDistricts <- 
  st_read("https://data.cityofchicago.org/api/geospatial/fthy-xz3r?method=export&format=GeoJSON") %>%
  st_transform('ESRI:102271') %>%
  dplyr::select(District = dist_num)
  
policeBeats <- 
  st_read("https://data.cityofchicago.org/api/geospatial/aerh-rz74?method=export&format=GeoJSON") %>%
  st_transform('ESRI:102271') %>%
  dplyr::select(District = beat_num)

bothPoliceUnits <- rbind(mutate(policeDistricts, Legend = "Police Districts"), 
                         mutate(policeBeats, Legend = "Police Beats"))

crimes <- 
  read.socrata("https://data.cityofchicago.org/d/w98m-zvie/") %>% 
    filter(Primary.Type == "ASSAULT") %>%
    mutate(x = gsub("[()]", "", Location)) %>%
    separate(x,into= c("Y","X"), sep=",") %>%
    mutate(X = as.numeric(X),Y = as.numeric(Y)) %>% 
    na.omit() %>%
    st_as_sf(coords = c("X", "Y"), crs = 4326, agr = "constant")%>%
    st_transform('ESRI:102271') %>% 
    distinct()

chicagoBoundary <- 
  st_read(file.path(root.dir,"/Chapter5/chicagoBoundary.geojson")) %>%
  st_transform('ESRI:102271') 
```
## 1.2 visualizing point data

The maps below in Figure 1.1 plot the point data of assaults and the overall density (areas with more assaults).

```{r fig.width=8, fig.height=6, message = FALSE}
# uses grid.arrange to organize indpendent plots
grid.arrange(ncol=2,
ggplot() + 
  geom_sf(data = chicagoBoundary) +
  geom_sf(data = crimes, colour="red", size=0.05, show.legend = "point") +
  labs(title= "Assaults, Chicago - 2019", caption = "Figure 1.1") +
  mapTheme(title_size = 14),

ggplot() + 
  geom_sf(data = chicagoBoundary, fill = "grey40") +
  stat_density2d(data = data.frame(st_coordinates(crimes)), 
                 aes(X, Y, fill = ..level.., alpha = ..level..),
                 size = 0.01, bins = 40, geom = 'polygon') +
  scale_fill_viridis() +
  scale_alpha(range = c(0.00, 0.35), guide = FALSE) +
  labs(title = "Density of Assaults")+
  mapTheme(title_size = 14) + theme(legend.position = "none"))
```

## 1.3 Creating a fishnet grid

I create a "fishnet" to examine data in an aggregate, dividing up Chicago into equally-sized squares; this is shown in Figure 1.3.

```{r, message = FALSE}
## using {sf} to create the grid
## Note the `.[chicagoBoundary] %>% ` line. This is needed to clip the grid to our data
fishnet <- 
  st_make_grid(chicagoBoundary,
               cellsize = 500, 
               square = TRUE) %>%
  .[chicagoBoundary] %>%            # <- MDH Added
  st_sf() %>%
  mutate(uniqueID = rownames(.))

ggplot()+
  geom_sf(data = chicagoBoundary, fill = "grey40") +
  geom_sf(data=fishnet)+
  labs(title="Fishnet Structure", 
       subtitle="Chicago, IL", 
       caption="Figure 1.2")+
  mapTheme()
```

### 1.3.1 Aggregate points to the fishnet

Below, in Figure 1.4, is the product of joining the crime points to the fishnet, where crimes have been allocated per cell.

```{r, message = FALSE}
## add a value of 1 to each crime, sum them with aggregate
crime_net <- 
  dplyr::select(crimes) %>% 
  mutate(countBurglaries = 1) %>% 
  aggregate(., fishnet, sum) %>%
  mutate(countBurglaries = replace_na(countBurglaries, 0),
         uniqueID = rownames(.),
         cvID = sample(round(nrow(fishnet) / 24), 
                       size=nrow(fishnet), replace = TRUE))

ggplot() +
  geom_sf(data = crime_net, aes(fill = countBurglaries), color = NA) +
  scale_fill_viridis() +
  labs(title = "Count of Assaults for the fishnet", caption = "Figure 1.3") +
  mapTheme()

# For demo. requires updated mapview package
# xx <- mapview::mapview(crime_net, zcol = "countBurglaries")
# yy <- mapview::mapview(mutate(burglaries, ID = seq(1:n())))
# xx + yy
```

## 2.1 Modeling Spatial Features

For possible features that might work as "risk factors," I pulled various 2019 point data from the City of Chicago OpenData portal, including information on abandoned cars, abandoned or vacant buildings, graffiti complains, street and alley light malfunction complaints, and sanitation complaints from the 311 database. I also pulled environmental factor complaints and liquor license information, mainly for liquor stores and places where liquor is consumed on-site (taverns, restaurant patios, "late hour" establishments, etc.).

These factors are plotted below with simple points; it is clear that there is a large contrast in the number of points reported for different variables, like lights out complaints and abandoned buildings.

### 2.1.1 Spatial Features, Chicago, 2019

```{r, message = FALSE, results=FALSE}
## Neighborhoods to use in LOOCV in a bit
neighborhoods <- 
  st_read("https://raw.githubusercontent.com/blackmad/neighborhoods/master/chicago.geojson") %>%
  st_transform(st_crs(fishnet)) 

## only pulling a single variable for our model to keep it simple
## using Socrata again
abandonCars <- 
  read.socrata("https://data.cityofchicago.org/Service-Requests/311-Service-Requests-Abandoned-Vehicles/3c9v-pnva") %>%
    mutate(year = substr(creation_date,1,4)) %>% filter(year == "2019") %>%
    dplyr::select(Y = latitude, X = longitude) %>%
    na.omit() %>%
    st_as_sf(coords = c("X", "Y"), crs = 4326, agr = "constant") %>%
    st_transform(st_crs(fishnet)) %>%
    mutate(Legend = "Abandoned_Cars")

abandonBuildings <- 
  read.csv("https://raw.githubusercontent.com/zoenyoo/MUSA508/main/Labs/MUSA_508_Lab-main/311_Service_Requests-Abandoned_buildings.csv") %>% 
  mutate(x = gsub("[()]", "", LOCATION)) %>%
    separate(x,into= c("Y","X"), sep=",") %>%
    mutate(X = as.numeric(X),Y = as.numeric(Y)) %>% 
    na.omit() %>%
    st_as_sf(coords = c("X", "Y"), crs = 4326, agr = "constant")%>%
    st_transform('ESRI:102271') %>% 
    distinct() %>% 
  mutate(Legend = "Abandoned_Buildings")

graffiti <- 
   read.csv("https://raw.githubusercontent.com/zoenyoo/MUSA508/main/Labs/MUSA_508_Lab-main/311_Graffiti18-19.csv") %>% 
  mutate(x = gsub("[()]", "", LOCATION)) %>%
    separate(x,into= c("Y","X"), sep=",") %>%
    mutate(X = as.numeric(X),Y = as.numeric(Y)) %>% 
    subset(!is.na(X)) %>%
    st_as_sf(coords = c("X", "Y"), crs = 4326, agr = "constant")%>%
    st_transform('ESRI:102271') %>% 
    distinct() %>% 
  mutate(Legend = "Graffiti")

lightsOut <-  #both alley and streets out
   read.csv("https://raw.githubusercontent.com/zoenyoo/MUSA508/main/Labs/MUSA_508_Lab-main/311_Service_Requests-lights-out.csv") %>% 
  mutate(x = gsub("[()]", "", LOCATION)) %>%
    separate(x,into= c("Y","X"), sep=",") %>%
    mutate(X = as.numeric(X),Y = as.numeric(Y)) %>% 
    subset(!is.na(X)) %>%
    st_as_sf(coords = c("X", "Y"), crs = 4326, agr = "constant")%>%
    st_transform('ESRI:102271') %>% 
    distinct() %>% 
  mutate(Legend = "Lights_Out")

liquorRetail <- 
  read.socrata("https://data.cityofchicago.org/resource/nrmj-3kcf.json") %>%  
    filter(business_activity == "Retail Sales of Packaged Liquor") %>%
    dplyr::select(Y = latitude, X = longitude) %>%
    na.omit() %>%
    st_as_sf(coords = c("X", "Y"), crs = 4326, agr = "constant") %>%
    st_transform(st_crs(fishnet)) %>%
    mutate(Legend = "Liquor_Retail")

liquorSite <- 
  read.csv("https://raw.githubusercontent.com/zoenyoo/MUSA508/main/Labs/MUSA_508_Lab-main/Liquor_onSite.csv") %>%  
    mutate(x = gsub("[()]", "", LOCATION)) %>%
    separate(x,into= c("Y","X"), sep=",") %>%
    mutate(X = as.numeric(X),Y = as.numeric(Y)) %>% 
    subset(!is.na(X)) %>%
    st_as_sf(coords = c("X", "Y"), crs = 4326, agr = "constant")%>%
    st_transform('ESRI:102271') %>% 
    distinct() %>% 
  mutate(Legend = "Liquor_OnSite")
  
sanitation <- #sanitation code violation
  read.csv("https://raw.githubusercontent.com/zoenyoo/MUSA508/main/Labs/MUSA_508_Lab-main/311_Service_Requests_scb.csv") %>%  
    mutate(x = gsub("[()]", "", LOCATION)) %>%
    separate(x,into= c("Y","X"), sep=",") %>%
    mutate(X = as.numeric(X),Y = as.numeric(Y)) %>% 
    subset(!is.na(X)) %>%
    st_as_sf(coords = c("X", "Y"), crs = 4326, agr = "constant")%>%
    st_transform('ESRI:102271') %>% 
    distinct() %>% 
  mutate(Legend = "Sanitation")
    
environment <- 
  read.socrata("https://data.cityofchicago.org/Environment-Sustainable-Development/CDPH-Environmental-Complaints/fypr-ksnz") %>%
    mutate(year = substr(complaint_date,1,4)) %>% filter(year == "2019") %>%
    dplyr::select(Y = latitude, X = longitude) %>%
    na.omit() %>%
    st_as_sf(coords = c("X", "Y"), crs = 4326, agr = "constant") %>%
    st_transform(st_crs(fishnet)) %>%
    mutate(Legend = "Environment")
```

```{r}

grid.arrange(ncol=4,nrow=2,
  ggplot() + 
  geom_sf(data = chicagoBoundary) +
  geom_sf(data = abandonCars, colour="black", size=0.1, show.legend = "point") +
  labs(title= "Abandoned Cars") +
  mapTheme(title_size = 10),
  ggplot() + 
  geom_sf(data = chicagoBoundary) +
  geom_sf(data = abandonBuildings, colour="black", size=0.1, show.legend = "point") +
  labs(title= "Abandoned Buildings") +
  mapTheme(title_size = 10),
  ggplot() + 
  geom_sf(data = chicagoBoundary) +
  geom_sf(data = graffiti, colour="black", size=0.1, show.legend = "point") +
  labs(title= "Graffiti Complaints") +
  mapTheme(title_size = 10),
  ggplot() + 
  geom_sf(data = chicagoBoundary) +
  geom_sf(data = lightsOut, colour="black", size=0.1, show.legend = "point") +
  labs(title= "Alley/Street Lights Out") +
  mapTheme(title_size = 10),
  ggplot() + 
  geom_sf(data = chicagoBoundary) +
  geom_sf(data = liquorRetail, colour="black", size=0.1, show.legend = "point") +
  labs(title= "Liquor Stores", caption = "Figure 2.1") +
  mapTheme(title_size = 10),
  ggplot() + 
  geom_sf(data = chicagoBoundary) +
  geom_sf(data = liquorSite, colour="black", size=0.1, show.legend = "point") +
  labs(title= "Liquor On-Site Consumption") +
  mapTheme(title_size = 10),
  ggplot() + 
  geom_sf(data = chicagoBoundary) +
  geom_sf(data = sanitation, colour="black", size=0.1, show.legend = "point") +
  labs(title= "Sanitation Complaints") +
  mapTheme(title_size = 10),
  ggplot() + 
  geom_sf(data = chicagoBoundary) +
  geom_sf(data = environment, colour="black", size=0.1, show.legend = "point") +
  labs(title= "Environmental Complaints") +
  mapTheme(title_size = 10))

```

### 2.1.2 Joining Data to the Fishnet

```{r, message = FALSE}

vars_net <- 
  rbind(abandonCars, liquorRetail, environment,
        dplyr::select(graffiti,Legend),
        dplyr::select(abandonBuildings,Legend),
        dplyr::select(lightsOut,Legend),
        dplyr::select(liquorSite,Legend),
        dplyr::select(sanitation,Legend)) %>%
  st_join(., fishnet, join=st_within) %>%
  st_drop_geometry() %>%
  group_by(uniqueID, Legend) %>%
  summarize(count = n()) %>%
    full_join(fishnet) %>%
    spread(Legend, count, fill=0) %>%
    st_sf() %>%
    dplyr::select(-`<NA>`) %>%
    na.omit() %>%
    ungroup()

# vars_net <- abandonCars %>%
#   spatially join abandonCars points to the fishnet polygon they are within %>%
#   drop the geometry attribute %>%
#   group_by each cells ID and the name of the feature %>%
#   summarize count the number of each point per grid cell %>%
#   join that summary back to spatial fishnet by cell ID %>%
#   "spread" from long to wide format and make column of our point count %>%
#   tell R that this should be an sf object %>%
#   remove a fussy column that appears b/c of NA %>%
#   get rid of rows with an NA in any column %>%
#   remove grouping so you are not tripped up later
```

## 3.1 Feature Engineering

Here, we use the nearest neighbor function to find the average distance to the nearest three neighbors of each point, which is then joined to the fishnet. Next, Figure 2.2 plots these for each risk variable. 

```{r, message = FALSE}
# convinience to reduce length of function names.
st_c    <- st_coordinates
st_coid <- st_centroid

## create NN from abandoned cars, liquor establishments, crashes, and graffiti
vars_net <- vars_net %>%
  mutate(abandonCars.nn = nn_function(st_c(st_coid(vars_net)), 
                                           st_c(abandonCars),
                                           k = 3)) %>% 
  mutate(abandonBuildings.nn = nn_function(st_c(st_coid(vars_net)), 
                                           st_c(abandonBuildings),
                                           k = 3)) %>% 
  mutate(graffiti.nn = nn_function(st_c(st_coid(vars_net)), 
                                           st_c(graffiti),
                                           k = 3)) %>% 
  mutate(lightsOut.nn = nn_function(st_c(st_coid(vars_net)), 
                                           st_c(lightsOut),
                                           k = 3)) %>% 
  mutate(liquorRetail.nn = nn_function(st_c(st_coid(vars_net)), 
                                           st_c(liquorRetail),
                                           k = 3)) %>% 
  mutate(liquorSite.nn = nn_function(st_c(st_coid(vars_net)), 
                                           st_c(liquorSite),
                                           k = 3)) %>% 
  mutate(sanitation.nn = nn_function(st_c(st_coid(vars_net)), 
                                           st_c(sanitation),
                                           k = 3)) %>% 
  mutate(environment.nn = nn_function(st_c(st_coid(vars_net)), 
                                           st_c(environment),
                                           k = 3))

```

```{r, fig.dim=c(8,6), message = FALSE}
## Visualize the NN feature
vars_net.long.nn <- 
  dplyr::select(vars_net, ends_with(".nn")) %>%
    gather(Variable, value, -geometry)

ggplot() +
      geom_sf(data = vars_net.long.nn , aes(fill=value), colour=NA) +
      facet_wrap(~Variable, nrow=2)+
      scale_fill_viridis(name="NN Distance") +
      labs(title="Nearest Neighbors Distance (ft)", caption = "Figure 3.1") +
      mapTheme() 

## important to drop the geometry from joining features
final_net <-
  left_join(crime_net, st_drop_geometry(vars_net), by="uniqueID")

final_net <-
  st_centroid(final_net) %>%
    st_join(dplyr::select(neighborhoods, name), by = "uniqueID") %>%
    st_join(dplyr::select(policeDistricts, District), by = "uniqueID") %>%
      st_drop_geometry() %>%
      left_join(dplyr::select(final_net, geometry, uniqueID)) %>%
      st_sf() %>% 
  na.omit()

```

Figure 3.2 shows the distribution of assaults by police district, the polygons of which I also pulled from Chicago OpenData.

```{r, message = FALSE}
ggplot(final_net, aes(District)) + 
    geom_bar() +
    labs(title="Distribution of Crimes by District", caption = "Figure 3.2",
         x="District Number", y="Count") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))+
  plotTheme()
```

## 3.2 Local Moran's I for fishnet grid cells

The below plots (in Figure 3.3) illustrate the local Moran's I for each variable, which were built using neighborhood weights.

```{r, message = FALSE}
## generates warnings from PROJ issues
## {spdep} to make polygon to neighborhoods... 
final_net.nb <- poly2nb(as_Spatial(final_net), queen=TRUE)
## ... and neighborhoods to list of weigths
final_net.weights <- nb2listw(final_net.nb, style="W", zero.policy=TRUE)

#print(final_net.weights, zero.policy=TRUE)
```

```{r, message = FALSE}
## see ?localmoran
local_morans <- localmoran(final_net$countBurglaries, final_net.weights, zero.policy=TRUE) %>% 
  as.data.frame()

# join local Moran's I results to fishnet
final_net.localMorans <- 
  cbind(local_morans, as.data.frame(final_net)) %>% 
  st_sf() %>%
  dplyr::select(Crime_Count = countBurglaries, 
                Local_Morans_I = Ii, 
                P_Value = `Pr(z != E(Ii))`) %>%
  mutate(Significant_Hotspots = ifelse(P_Value <= 0.001, 1, 0)) %>%
  gather(Variable, Value, -geometry)
  
```

```{r, message = FALSE}
## This is just for plotting
vars <- unique(final_net.localMorans$Variable)
varList <- list()

for(i in vars){
  varList[[i]] <- 
    ggplot() +
      geom_sf(data = filter(final_net.localMorans, Variable == i), 
              aes(fill = Value), colour=NA) +
      scale_fill_viridis(name="") +
      labs(title=i) +
      mapTheme(title_size = 14) + theme(legend.position="bottom")}

do.call(grid.arrange,c(varList, ncol = 4, top = "Local Moran's I Statistics"))
```
*Figure 3.3*

## 3.3 Correlation Tests

Figure 3.4 contains multiple scatterplots for all the possible correlating risk factors, which aids in choosing which to incorporate into the model.

```{r, message = FALSE}
# generates warning from NN
final_net <- final_net %>% 
  mutate(abandoned.isSig = 
           ifelse(local_morans[,5] <= 0.001, 1, 0)) %>%
  mutate(abandoned.isSig.dist = 
           nn_function(st_c(st_coid(final_net)),
                       st_c(st_coid(filter(final_net, 
                                           abandoned.isSig == 1))), 
                       k = 1))

## What does k = 1 represent?
```

```{r, fig.width=8, fig.height=10, message = FALSE}

correlation.long <-
  st_drop_geometry(final_net) %>%
    dplyr::select(-uniqueID, -cvID, -name, -District, -abandoned.isSig, -abandoned.isSig.dist) %>%
    gather(Variable, Value, -countBurglaries)

correlation.cor <-
  correlation.long %>%
    group_by(Variable) %>%
    summarize(correlation = cor(Value, countBurglaries, use = "complete.obs"))
    
ggplot(correlation.long, aes(Value, countBurglaries)) +
  geom_point(size = 0.1) +
  geom_text(data = correlation.cor, aes(label = paste("r =", round(correlation, 2))),
            x=-Inf, y=Inf, vjust = 1.5, hjust = -.1) +
  geom_smooth(method = "lm", se = FALSE, colour = "black") +
  facet_wrap(~Variable, ncol = 4, scales = "free") +
  labs(title = "Assault count as a function of risk factors", caption = "Figure 3.4") +
  plotTheme()

```
## 3.4 Accuracy

### 3.4.1 Mean Absolute Error Histogram

The table below, as well as Figure 3.6, illustrate mean absolute error and the standard deviation of mean absolute error per regression.

```{r, message = FALSE, results=FALSE, warning=FALSE}
# calculate errors by NEIGHBORHOOD
reg.vars <- c("abandonCars.nn", "abandonBuildings.nn", "graffiti.nn","lightsOut.nn", 
              "liquorRetail.nn", "liquorSite.nn", "sanitation.nn", 
              "environment.nn")

reg.ss.vars <- c("abandonCars.nn", "abandonBuildings.nn", "graffiti.nn","lightsOut.nn",
              "liquorRetail.nn", "liquorSite.nn", "sanitation.nn", 
              "environment.nn", "abandoned.isSig.dist")

## RUN REGRESSIONS
reg.cv <- crossValidate(
  dataset = final_net,
  id = "cvID",
  dependentVariable = "countBurglaries",
  indVariables = reg.vars) %>%
    dplyr::select(cvID = cvID, countBurglaries, Prediction, geometry)

reg.ss.cv <- crossValidate(
  dataset = final_net,
  id = "cvID",
  dependentVariable = "countBurglaries",
  indVariables = reg.ss.vars) %>%
    dplyr::select(cvID = cvID, countBurglaries, Prediction, geometry)
  
reg.spatialCV <- crossValidate(
  dataset = final_net,
  id = "name",
  dependentVariable = "countBurglaries",
  indVariables = reg.vars) %>%
    dplyr::select(cvID = name, countBurglaries, Prediction, geometry)

reg.ss.spatialCV <- crossValidate(
  dataset = final_net,
  id = "name",
  dependentVariable = "countBurglaries",
  indVariables = reg.ss.vars) %>%
    dplyr::select(cvID = name, countBurglaries, Prediction, geometry)


reg.summary <- 
  rbind(
    mutate(reg.cv,           Error = Prediction - countBurglaries,
                             Regression = "Random k-fold CV: Just Risk Factors"),
                             
    mutate(reg.ss.cv,        Error = Prediction - countBurglaries,
                             Regression = "Random k-fold CV: Spatial Process"),
    
    mutate(reg.spatialCV,    Error = Prediction - countBurglaries,
                             Regression = "Spatial LOGO-CV: Just Risk Factors"),
                             
    mutate(reg.ss.spatialCV, Error = Prediction - countBurglaries,
                             Regression = "Spatial LOGO-CV: Spatial Process")) %>%
    st_sf() 

error_by_reg_and_fold <- 
  reg.summary %>%
    group_by(Regression, cvID) %>% 
    summarize(Mean_Error = mean(Prediction - countBurglaries, na.rm = T),
              MAE = mean(abs(Mean_Error), na.rm = T),
              SD_MAE = mean(abs(Mean_Error), na.rm = T)) %>%
  ungroup()


```

```{r}
error_by_reg_and_fold %>%
  ggplot(aes(MAE)) + 
    geom_histogram(bins = 30, colour="black", fill = "#FDE725FF") +
    facet_wrap(~Regression) +  
    geom_vline(xintercept = 0) + scale_x_continuous(breaks = seq(0, 8, by = 1)) + 
    labs(title="Distribution of MAE", subtitle = "k-fold cross validation vs. LOGO-CV",
         x="Mean Absolute Error", y="Count", caption = "Figure 3.5") +
    plotTheme()
```
### 3.4.2 MAE Table

```{r, message = FALSE}

st_drop_geometry(error_by_reg_and_fold) %>%
  group_by(Regression) %>% 
    summarize(Mean_MAE = round(mean(MAE), 2),
              SD_MAE = round(sd(MAE), 2)) %>%
  kable(caption = "Figure 3.6") %>%
    kable_styling("striped", full_width = F) %>%
    row_spec(2, color = "black", background = "#FDE725FF") %>%
    row_spec(4, color = "black", background = "#FDE725FF") 

```

### 3.4.3 Multiple Mapping Error by Regression Type

In Figure 3.7, the errors for spatial LOGO-CV regression are compared to the errors from the random k-fold regression.

```{r,message = FALSE}
grid.arrange(nrow=1,
  ggplot(error_by_reg_and_fold %>% filter(str_detect(Regression, "LOGO"))) +
    geom_sf(aes(fill = MAE)) +
    facet_wrap(~Regression) +
    scale_fill_viridis() +
    labs(title = "Assault errors by LOGO-CV Regression", caption="Figure 3.7") +
    mapTheme(title_size = 12) + theme(legend.position="bottom"),
  
  ggplot(error_by_reg_and_fold %>% filter(str_detect(Regression, "k-fold"))) +
    geom_sf(aes(fill = MAE)) +
    facet_wrap(~Regression) +
    scale_fill_viridis() +
    labs(title = "Assault errors by k-fold Regression", caption = " ") +
    mapTheme(title_size = 12) + theme(legend.position="bottom"))
```
### 3.4.4 Error by Race Context

```{r, message = FALSE, results=FALSE}

tracts19 <- 
  get_acs(geography = "tract", variables = c("B01001_001E","B01001A_001E"), 
          year = 2019, state=17, county=031, geometry=T) %>%
  st_transform('ESRI:102271')  %>% 
  dplyr::select(variable, estimate, GEOID) %>%
  spread(variable, estimate) %>%
  rename(TotalPop = B01001_001,
         NumberWhites = B01001A_001) %>%
  mutate(percentWhite = NumberWhites / TotalPop,
         raceContext = ifelse(percentWhite > .5, "Majority_White", "Majority_Non_White")) %>%
  .[neighborhoods,]

```

```{r}
reg.summary %>% 
    st_centroid() %>%
    st_join(tracts19) %>%
    na.omit() %>%
      st_drop_geometry() %>%
      group_by(Regression, raceContext) %>%
      summarize(mean.Error = mean(Error, na.rm = T)) %>%
      spread(raceContext, mean.Error) %>%
      kable(caption = "Figure 3.8 - Mean Error by Neighborhood Racial Context") %>%
        kable_styling("striped", full_width = F)  

```


## 4.1 Kernel Density Estimates

Kernel density is another way to measure density of crimes, that is based on the occurence of nearby points under a defined curve. In Figure 4.1, kernel density is shown for our Chicago assault 2019 data for a curve of 1000 feet.

```{r,message = FALSE}
# demo of kernel width
crim_ppp <- as.ppp(st_coordinates(crimes), W = st_bbox(final_net))
crim_KD.1000 <- spatstat.core::density.ppp(crim_ppp, 1000)
crim_KD.1500 <- spatstat.core::density.ppp(crim_ppp, 1500)
crim_KD.2000 <- spatstat.core::density.ppp(crim_ppp, 2000)
crim_KD.df <- rbind(
  mutate(data.frame(rasterToPoints(mask(raster(crim_KD.1000), as(neighborhoods, 'Spatial')))), Legend = "1000 Ft."),
  mutate(data.frame(rasterToPoints(mask(raster(crim_KD.1500), as(neighborhoods, 'Spatial')))), Legend = "1500 Ft."),
  mutate(data.frame(rasterToPoints(mask(raster(crim_KD.2000), as(neighborhoods, 'Spatial')))), Legend = "2000 Ft.")) 

crim_KD.df$Legend <- factor(crim_KD.df$Legend, levels = c("1000 Ft.", "1500 Ft.", "2000 Ft."))

as.data.frame(crim_KD.1000) %>%
  st_as_sf(coords = c("x", "y"), crs = st_crs(final_net)) %>%
  aggregate(., final_net, mean) %>%
   ggplot() +
     geom_sf(aes(fill=value)) +
     geom_sf(data = sample_n(crimes, 1500), size = .5) +
     scale_fill_viridis(name = "Density") +
     labs(title = "Kernel density of 2019 Assaults", caption = "Figure 4.1") +
     mapTheme(title_size = 14)

```

## 4.2 Comparing with 2020 Crime Data

Here, I compare how the spatial process, spatial LOGO-CV model performs relative to kernel density on the assault data from 2020. Figure 4.2 maps this relationship, while Figure 4.3 illustrates the rate of crimes by risk category, both for kernel density and risk predictions.

```{r, message = FALSE}

crimes20 <- 
  read.socrata("https://data.cityofchicago.org/Public-Safety/Crimes-2020/qzdf-xmn8") %>% 
    filter(Primary.Type == "ASSAULT") %>%
    mutate(x = gsub("[()]", "", Location)) %>%
    separate(x,into= c("Y","X"), sep=",") %>%
    mutate(X = as.numeric(X),Y = as.numeric(Y)) %>% 
    na.omit() %>%
    st_as_sf(coords = c("X", "Y"), crs = 4326, agr = "constant")%>%
    st_transform('ESRI:102271') %>% 
    distinct() %>% .[fishnet,]

crim_ppp <- as.ppp(st_coordinates(crimes), W = st_bbox(final_net))

crim_KDE_sf <- as.data.frame(crim_KD.1000) %>%
  st_as_sf(coords = c("x", "y"), crs = st_crs(final_net)) %>%
  aggregate(., final_net, mean) %>%
  mutate(label = "Kernel Density",
         Risk_Category = ntile(value, 100),
         Risk_Category = case_when(
           Risk_Category >= 90 ~ "90% to 100%",
           Risk_Category >= 70 & Risk_Category <= 89 ~ "70% to 89%",
           Risk_Category >= 50 & Risk_Category <= 69 ~ "50% to 69%",
           Risk_Category >= 30 & Risk_Category <= 49 ~ "30% to 49%",
           Risk_Category >= 1 & Risk_Category <= 29 ~ "1% to 29%")) %>%
  cbind(
    aggregate(
      dplyr::select(crimes20) %>% mutate(burgCount = 1), ., sum) %>%
    mutate(burgCount = replace_na(burgCount, 0))) %>%
  dplyr::select(label, Risk_Category, burgCount)

crim_risk_sf <-
  reg.ss.spatialCV %>%
  mutate(label = "Risk Predictions",
         Risk_Category = ntile(Prediction, 100),
         Risk_Category = case_when(
         Risk_Category >= 90 ~ "90% to 100%",
         Risk_Category >= 70 & Risk_Category <= 89 ~ "70% to 89%",
         Risk_Category >= 50 & Risk_Category <= 69 ~ "50% to 69%",
         Risk_Category >= 30 & Risk_Category <= 49 ~ "30% to 49%",
         Risk_Category >= 1 & Risk_Category <= 29 ~ "1% to 29%")) %>%
  cbind(
    aggregate(
      dplyr::select(crimes20) %>% mutate(burgCount = 1), ., sum) %>%
      mutate(burgCount = replace_na(burgCount, 0))) %>%
  dplyr::select(label,Risk_Category, burgCount)

rbind(crim_KDE_sf, crim_risk_sf) %>%
  na.omit() %>% 
  gather(Variable, Value, -label, -Risk_Category, -geometry) %>%
  ggplot() +
    geom_sf(aes(fill = Risk_Category), colour = NA) +
    geom_sf(data = sample_n(crimes20, 3000), size = .5, colour = "black") +
    facet_wrap(~label, ) +
    scale_fill_viridis(discrete = TRUE) +
    labs(title="Comparison of Kernel Density and Risk Predictions",
         subtitle="2019 Assault Risk Predictions; 2020 Assaults",
         caption="Figure 4.2") +
    mapTheme(title_size = 14)
```

```{r, message = FALSE}
rbind(crim_KDE_sf, crim_risk_sf) %>%
  st_set_geometry(NULL) %>% na.omit() %>%
  gather(Variable, Value, -label, -Risk_Category) %>%
  group_by(label, Risk_Category) %>%
  summarize(countBurglaries = sum(Value)) %>%
  ungroup() %>%
  group_by(label) %>%
  mutate(Rate_of_test_set_crimes = countBurglaries / sum(countBurglaries)) %>%
    ggplot(aes(Risk_Category,Rate_of_test_set_crimes)) +
      geom_bar(aes(fill=label), position="dodge", stat="identity") +
      scale_fill_viridis(discrete = TRUE) +
      labs(title = "Risk prediction vs. Kernel density, 2018 burglaries") +
      theme(axis.text.x = element_text(angle = 45, vjust = 0.5))
```

## 5.1 Conclusions

Since the spatial LOGO-CV model does generalize fairly well in its risk predictions across actual kernel density, relative to the crime data, this model may have some use in predicting assault locations. However, though it predicts well for "high risk" categories, the presence of selection bias cannot be completely ruled out. As mentioned before, police discretion over whether to arrest people for assault is far more inconsistent than for crimes such as burglary. Any selection bias could lead this model to be less accurate, or to predict in areas that police already *expect* assaults to be, and thus patrol more attentively in.

The model also has consistent errors that are diverted depending on whether a neighborhood is majority-white or non-white. This may be problematic, as if error that correlates with race is present, use of this model may lead to under- or over-policing of certain neighborhoods. Since over-policing in non-white neighborhoods and racial bias in arrests are major community concerns, I would suggest that more work be done to minimize the disparity in error by race, as well as considering other possible bias factors like income, before putting this model into practice.